{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a17471b0",
   "metadata": {},
   "source": [
    "> Solve Kuramotoâ€“Sivashinsky with PIML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84a99c2",
   "metadata": {},
   "source": [
    "<center>$\\large \\frac{\\partial u}{\\partial t}=-v\\frac{\\partial^4 u}{\\partial x^4}-\\frac{\\partial^2 u}{\\partial x^2}-u\\frac{\\partial u}{\\partial x}$</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4db2805d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import progressbar\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e7bc2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_parquet('Data/KS_data.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e622e10",
   "metadata": {},
   "source": [
    "Scaling the data or PCA won't work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22cf7bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "data = pd.DataFrame(scaler.fit_transform(data))\n",
    "data = data.applymap(lambda n: (n + 1) / 2) # set all values bewteen 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7287ebe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.478193</td>\n",
       "      <td>-0.423484</td>\n",
       "      <td>-0.361481</td>\n",
       "      <td>-0.294564</td>\n",
       "      <td>-0.224610</td>\n",
       "      <td>-0.153012</td>\n",
       "      <td>-0.080711</td>\n",
       "      <td>-0.008241</td>\n",
       "      <td>0.064236</td>\n",
       "      <td>0.136886</td>\n",
       "      <td>0.210136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.422947</td>\n",
       "      <td>-0.359123</td>\n",
       "      <td>-0.291522</td>\n",
       "      <td>-0.221948</td>\n",
       "      <td>-0.151654</td>\n",
       "      <td>-0.081407</td>\n",
       "      <td>-0.011565</td>\n",
       "      <td>0.057864</td>\n",
       "      <td>0.127159</td>\n",
       "      <td>0.196825</td>\n",
       "      <td>0.267534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.355469</td>\n",
       "      <td>-0.286757</td>\n",
       "      <td>-0.217152</td>\n",
       "      <td>-0.147817</td>\n",
       "      <td>-0.079377</td>\n",
       "      <td>-0.012018</td>\n",
       "      <td>0.054417</td>\n",
       "      <td>0.120348</td>\n",
       "      <td>0.186393</td>\n",
       "      <td>0.253301</td>\n",
       "      <td>0.321885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.280954</td>\n",
       "      <td>-0.210939</td>\n",
       "      <td>-0.142184</td>\n",
       "      <td>-0.075218</td>\n",
       "      <td>-0.010091</td>\n",
       "      <td>0.053510</td>\n",
       "      <td>0.116160</td>\n",
       "      <td>0.178607</td>\n",
       "      <td>0.241705</td>\n",
       "      <td>0.306349</td>\n",
       "      <td>0.373406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.204034</td>\n",
       "      <td>-0.135486</td>\n",
       "      <td>-0.069613</td>\n",
       "      <td>-0.006376</td>\n",
       "      <td>0.054664</td>\n",
       "      <td>0.114221</td>\n",
       "      <td>0.173183</td>\n",
       "      <td>0.232528</td>\n",
       "      <td>0.293251</td>\n",
       "      <td>0.356305</td>\n",
       "      <td>0.422529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.128438</td>\n",
       "      <td>-0.063269</td>\n",
       "      <td>-0.001522</td>\n",
       "      <td>0.057319</td>\n",
       "      <td>0.114079</td>\n",
       "      <td>0.169773</td>\n",
       "      <td>0.225505</td>\n",
       "      <td>0.282389</td>\n",
       "      <td>0.341478</td>\n",
       "      <td>0.403704</td>\n",
       "      <td>0.469814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.056850</td>\n",
       "      <td>0.003817</td>\n",
       "      <td>0.060877</td>\n",
       "      <td>0.115222</td>\n",
       "      <td>0.167962</td>\n",
       "      <td>0.220317</td>\n",
       "      <td>0.273522</td>\n",
       "      <td>0.328744</td>\n",
       "      <td>0.387020</td>\n",
       "      <td>0.449199</td>\n",
       "      <td>0.515869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.009049</td>\n",
       "      <td>0.064755</td>\n",
       "      <td>0.117113</td>\n",
       "      <td>0.167289</td>\n",
       "      <td>0.216590</td>\n",
       "      <td>0.266360</td>\n",
       "      <td>0.317883</td>\n",
       "      <td>0.372313</td>\n",
       "      <td>0.430609</td>\n",
       "      <td>0.493473</td>\n",
       "      <td>0.561285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.068433</td>\n",
       "      <td>0.119234</td>\n",
       "      <td>0.167275</td>\n",
       "      <td>0.213910</td>\n",
       "      <td>0.260565</td>\n",
       "      <td>0.308631</td>\n",
       "      <td>0.359380</td>\n",
       "      <td>0.413892</td>\n",
       "      <td>0.472988</td>\n",
       "      <td>0.537174</td>\n",
       "      <td>0.606572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.121133</td>\n",
       "      <td>0.167462</td>\n",
       "      <td>0.211848</td>\n",
       "      <td>0.255763</td>\n",
       "      <td>0.300679</td>\n",
       "      <td>0.347975</td>\n",
       "      <td>0.398855</td>\n",
       "      <td>0.454267</td>\n",
       "      <td>0.514849</td>\n",
       "      <td>0.580858</td>\n",
       "      <td>0.652112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.167451</td>\n",
       "      <td>0.209994</td>\n",
       "      <td>0.251565</td>\n",
       "      <td>0.293683</td>\n",
       "      <td>0.337813</td>\n",
       "      <td>0.385267</td>\n",
       "      <td>0.437127</td>\n",
       "      <td>0.494165</td>\n",
       "      <td>0.556782</td>\n",
       "      <td>0.624947</td>\n",
       "      <td>0.698128</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6   \\\n",
       "0  -0.478193 -0.423484 -0.361481 -0.294564 -0.224610 -0.153012 -0.080711   \n",
       "1  -0.422947 -0.359123 -0.291522 -0.221948 -0.151654 -0.081407 -0.011565   \n",
       "2  -0.355469 -0.286757 -0.217152 -0.147817 -0.079377 -0.012018  0.054417   \n",
       "3  -0.280954 -0.210939 -0.142184 -0.075218 -0.010091  0.053510  0.116160   \n",
       "4  -0.204034 -0.135486 -0.069613 -0.006376  0.054664  0.114221  0.173183   \n",
       "5  -0.128438 -0.063269 -0.001522  0.057319  0.114079  0.169773  0.225505   \n",
       "6  -0.056850  0.003817  0.060877  0.115222  0.167962  0.220317  0.273522   \n",
       "7   0.009049  0.064755  0.117113  0.167289  0.216590  0.266360  0.317883   \n",
       "8   0.068433  0.119234  0.167275  0.213910  0.260565  0.308631  0.359380   \n",
       "9   0.121133  0.167462  0.211848  0.255763  0.300679  0.347975  0.398855   \n",
       "10  0.167451  0.209994  0.251565  0.293683  0.337813  0.385267  0.437127   \n",
       "\n",
       "          7         8         9         10  \n",
       "0  -0.008241  0.064236  0.136886  0.210136  \n",
       "1   0.057864  0.127159  0.196825  0.267534  \n",
       "2   0.120348  0.186393  0.253301  0.321885  \n",
       "3   0.178607  0.241705  0.306349  0.373406  \n",
       "4   0.232528  0.293251  0.356305  0.422529  \n",
       "5   0.282389  0.341478  0.403704  0.469814  \n",
       "6   0.328744  0.387020  0.449199  0.515869  \n",
       "7   0.372313  0.430609  0.493473  0.561285  \n",
       "8   0.413892  0.472988  0.537174  0.606572  \n",
       "9   0.454267  0.514849  0.580858  0.652112  \n",
       "10  0.494165  0.556782  0.624947  0.698128  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[:10, :10]  # just an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb62dad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "go.Figure(data =\n",
    "    go.Contour(\n",
    "        z=data.loc[:1000].to_numpy()\n",
    "    )).write_image('images/problem_3_data_example.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4b7a86",
   "metadata": {},
   "source": [
    "![](images/problem_3_data_example.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58042043",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_n_components_acc(n, data):\n",
    "    pca = PCA(n_components=n)\n",
    "    reduced_data = pca.fit_transform(data)\n",
    "    aux = pca.inverse_transform(reduced_data)\n",
    "    return mean_absolute_error(data, aux)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f839a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41% (20 of 48) |##########              | Elapsed Time: 0:01:38 ETA:   0:02:27"
     ]
    }
   ],
   "source": [
    "pca_n_acc = []\n",
    "for i in progressbar.progressbar(range(2, 50)):\n",
    "    pca_n_acc.append(test_n_components_acc(i, data))\n",
    "\n",
    "# I started with n_components up to 50 above, but results were bad even for 50, I just extended the test\n",
    "# in order to save time, that's why the X of the chart looks like that\n",
    "\n",
    "for i in progressbar.progressbar(range(50, 200, 10)):\n",
    "    pca_n_acc.append(test_n_components_acc(i, data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bc2631",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line(x=[*range(2, 50), *range(50, 200, 10)], y=pca_n_acc,\n",
    "        title='Reduced data difference to real').write_image('images/PCA_components_test.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8a9126",
   "metadata": {},
   "source": [
    "![](images/PCA_components_test.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3ff79b",
   "metadata": {},
   "source": [
    "I'll use 90 as the number of components, that's the first one where the difference to original on return is negligible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ebb5a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85a66284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 58.2 s\n",
      "Wall time: 5.75 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "reduced_data = pca.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88cc0034",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0006817918148951832"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(data, pca.inverse_transform(reduced_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be54fc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_data = pd.DataFrame(reduced_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230c57a7",
   "metadata": {},
   "source": [
    "scale the reduced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d855bbe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "red_scaler = StandardScaler()\n",
    "reduced_data = pd.DataFrame(red_scaler.fit_transform(reduced_data))\n",
    "reduced_data = reduced_data.applymap(lambda n: (n + 1) / 2) # set all values bewteen 0 and 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ffe87c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca196a3",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee08b6e",
   "metadata": {},
   "source": [
    "I want to try a LSTM, gonna start with a relatively tame one"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3ac68e",
   "metadata": {},
   "source": [
    "reshape data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e8ed248",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 1000\n",
    "X, y = [], []\n",
    "for i in range(len(reduced_data) - (sample_size + 1)):\n",
    "    X.append(reduced_data.loc[i:i + sample_size - 1].to_numpy())\n",
    "    y.append(reduced_data.loc[i + sample_size].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "11ccf8de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(198999, 198999)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X), len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1753d358",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9004a60e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_1 (LSTM)               (None, 128)               112128    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 90)                11610     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 123,738\n",
      "Trainable params: 123,738\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(layers.LSTM(128, input_shape=(1000, 90)))\n",
    "model.add(layers.Dense(90))\n",
    "model.compile()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "034942d9",
   "metadata": {},
   "outputs": [
    {
     "ename": "InternalError",
     "evalue": "Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "Input \u001b[1;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[0;32m      3\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:102\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m    100\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[0;32m    101\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m--> 102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mInternalError\u001b[0m: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized."
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train, y_train, validation_data=(X_test, y_test), batch_size=1, epochs=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14e7b9e",
   "metadata": {},
   "source": [
    "So the model is eating my whole vram even with batch_size = 1, there's no way I'm running this. Will change my approach to DeepONets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d7b73f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa56474",
   "metadata": {},
   "source": [
    "### DeepONets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8c4aa155",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DeepXDE backend not selected or invalid. Use tensorflow.compat.v1.\n",
      "Using backend: tensorflow.compat.v1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting the default backend to \"tensorflow.compat.v1\". You can change it in the ~/.deepxde/config.json file or export the DDE_BACKEND environment variable. Valid options are: tensorflow.compat.v1, tensorflow, pytorch, jax, paddle (all lowercase)\n",
      "WARNING:tensorflow:From C:\\Users\\Lucas\\anaconda3\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "Enable just-in-time compilation with XLA.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Lucas\\anaconda3\\lib\\site-packages\\deepxde\\nn\\initializers.py:118: The name tf.keras.initializers.he_normal is deprecated. Please use tf.compat.v1.keras.initializers.he_normal instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import deepxde as dde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "815f0757",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The training dataset does not have the format of Cartesian product.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [27]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mdde\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTripleCartesianProd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\deepxde\\data\\triple.py:63\u001b[0m, in \u001b[0;36mTripleCartesianProd.__init__\u001b[1;34m(self, X_train, y_train, X_test, y_test)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X_train, y_train, X_test, y_test):\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(X_train[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(X_train[\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;241m!=\u001b[39m y_train\u001b[38;5;241m.\u001b[39msize:\n\u001b[1;32m---> 63\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     64\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe training dataset does not have the format of Cartesian product.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     65\u001b[0m         )\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(X_test[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(X_test[\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;241m!=\u001b[39m y_test\u001b[38;5;241m.\u001b[39msize:\n\u001b[0;32m     67\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     68\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe testing dataset does not have the format of Cartesian product.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     69\u001b[0m         )\n",
      "\u001b[1;31mValueError\u001b[0m: The training dataset does not have the format of Cartesian product."
     ]
    }
   ],
   "source": [
    "data = dde.data.TripleCartesianProd(X_train, np.array(y_train), X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18accc33",
   "metadata": {},
   "source": [
    "I have no idea what shape is the input expected to be in, [the docs are vague](https://deepxde.readthedocs.io/en/latest/modules/deepxde.data.html#deepxde.data.triple.TripleCartesianProd) and [the examples are no better](https://deepxde.readthedocs.io/en/latest/demos/operator/antiderivative_aligned.html#complete-code)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83d6c76",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4d4f3f",
   "metadata": {},
   "source": [
    "### OpInf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69233d23",
   "metadata": {},
   "source": [
    "[Willcox-Research-Group OpInf looks good and has docs, gonna try it](https://willcox-research-group.github.io/rom-operator-inference-Python3/content/index.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "971ff546",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>80</th>\n",
       "      <th>81</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "      <th>85</th>\n",
       "      <th>86</th>\n",
       "      <th>87</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.060983</td>\n",
       "      <td>-0.249232</td>\n",
       "      <td>0.033320</td>\n",
       "      <td>-0.003673</td>\n",
       "      <td>0.717194</td>\n",
       "      <td>1.046063</td>\n",
       "      <td>0.610880</td>\n",
       "      <td>0.881125</td>\n",
       "      <td>-0.095760</td>\n",
       "      <td>1.208036</td>\n",
       "      <td>...</td>\n",
       "      <td>1.287039</td>\n",
       "      <td>0.835713</td>\n",
       "      <td>0.230009</td>\n",
       "      <td>0.408131</td>\n",
       "      <td>0.915408</td>\n",
       "      <td>0.979728</td>\n",
       "      <td>0.321034</td>\n",
       "      <td>-0.053301</td>\n",
       "      <td>0.046553</td>\n",
       "      <td>0.741576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.055380</td>\n",
       "      <td>-0.241545</td>\n",
       "      <td>0.043931</td>\n",
       "      <td>-0.020404</td>\n",
       "      <td>0.787182</td>\n",
       "      <td>1.059425</td>\n",
       "      <td>0.642775</td>\n",
       "      <td>0.824348</td>\n",
       "      <td>-0.074474</td>\n",
       "      <td>1.230836</td>\n",
       "      <td>...</td>\n",
       "      <td>1.288494</td>\n",
       "      <td>0.949028</td>\n",
       "      <td>0.215377</td>\n",
       "      <td>0.419659</td>\n",
       "      <td>0.920888</td>\n",
       "      <td>0.938208</td>\n",
       "      <td>0.465689</td>\n",
       "      <td>-0.180783</td>\n",
       "      <td>-0.155095</td>\n",
       "      <td>0.738815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.049613</td>\n",
       "      <td>-0.227252</td>\n",
       "      <td>0.060362</td>\n",
       "      <td>-0.036550</td>\n",
       "      <td>0.858226</td>\n",
       "      <td>1.069472</td>\n",
       "      <td>0.671495</td>\n",
       "      <td>0.763695</td>\n",
       "      <td>-0.057550</td>\n",
       "      <td>1.249672</td>\n",
       "      <td>...</td>\n",
       "      <td>1.297449</td>\n",
       "      <td>1.066072</td>\n",
       "      <td>0.201506</td>\n",
       "      <td>0.379826</td>\n",
       "      <td>0.869458</td>\n",
       "      <td>0.857093</td>\n",
       "      <td>0.613904</td>\n",
       "      <td>-0.254435</td>\n",
       "      <td>-0.353925</td>\n",
       "      <td>0.800326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.043500</td>\n",
       "      <td>-0.206530</td>\n",
       "      <td>0.082012</td>\n",
       "      <td>-0.051347</td>\n",
       "      <td>0.929366</td>\n",
       "      <td>1.075283</td>\n",
       "      <td>0.696153</td>\n",
       "      <td>0.701332</td>\n",
       "      <td>-0.045229</td>\n",
       "      <td>1.264819</td>\n",
       "      <td>...</td>\n",
       "      <td>1.295591</td>\n",
       "      <td>1.155701</td>\n",
       "      <td>0.167765</td>\n",
       "      <td>0.301866</td>\n",
       "      <td>0.753864</td>\n",
       "      <td>0.760580</td>\n",
       "      <td>0.732424</td>\n",
       "      <td>-0.240733</td>\n",
       "      <td>-0.494130</td>\n",
       "      <td>0.924109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.036902</td>\n",
       "      <td>-0.179899</td>\n",
       "      <td>0.108162</td>\n",
       "      <td>-0.063958</td>\n",
       "      <td>0.999676</td>\n",
       "      <td>1.076241</td>\n",
       "      <td>0.715926</td>\n",
       "      <td>0.639420</td>\n",
       "      <td>-0.037566</td>\n",
       "      <td>1.276671</td>\n",
       "      <td>...</td>\n",
       "      <td>1.260132</td>\n",
       "      <td>1.200473</td>\n",
       "      <td>0.100077</td>\n",
       "      <td>0.216509</td>\n",
       "      <td>0.589493</td>\n",
       "      <td>0.684383</td>\n",
       "      <td>0.785061</td>\n",
       "      <td>-0.133949</td>\n",
       "      <td>-0.528797</td>\n",
       "      <td>1.082124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199995</th>\n",
       "      <td>0.064257</td>\n",
       "      <td>0.065702</td>\n",
       "      <td>0.992203</td>\n",
       "      <td>0.557008</td>\n",
       "      <td>0.867911</td>\n",
       "      <td>0.322929</td>\n",
       "      <td>0.235827</td>\n",
       "      <td>1.436795</td>\n",
       "      <td>0.970282</td>\n",
       "      <td>1.104490</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.346586</td>\n",
       "      <td>-0.566914</td>\n",
       "      <td>1.144641</td>\n",
       "      <td>0.126556</td>\n",
       "      <td>0.530678</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>-0.623557</td>\n",
       "      <td>0.313669</td>\n",
       "      <td>-0.228914</td>\n",
       "      <td>0.821861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199996</th>\n",
       "      <td>0.087371</td>\n",
       "      <td>0.072969</td>\n",
       "      <td>1.004596</td>\n",
       "      <td>0.553764</td>\n",
       "      <td>0.878036</td>\n",
       "      <td>0.313668</td>\n",
       "      <td>0.224850</td>\n",
       "      <td>1.444529</td>\n",
       "      <td>0.967536</td>\n",
       "      <td>1.095734</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.320804</td>\n",
       "      <td>-0.582517</td>\n",
       "      <td>1.124550</td>\n",
       "      <td>0.190273</td>\n",
       "      <td>0.459681</td>\n",
       "      <td>0.720689</td>\n",
       "      <td>-0.654188</td>\n",
       "      <td>0.369592</td>\n",
       "      <td>-0.232887</td>\n",
       "      <td>0.751271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199997</th>\n",
       "      <td>0.109518</td>\n",
       "      <td>0.079295</td>\n",
       "      <td>1.017653</td>\n",
       "      <td>0.551714</td>\n",
       "      <td>0.887140</td>\n",
       "      <td>0.306317</td>\n",
       "      <td>0.214181</td>\n",
       "      <td>1.453414</td>\n",
       "      <td>0.963708</td>\n",
       "      <td>1.087367</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.283037</td>\n",
       "      <td>-0.588845</td>\n",
       "      <td>1.101614</td>\n",
       "      <td>0.253078</td>\n",
       "      <td>0.401736</td>\n",
       "      <td>0.695244</td>\n",
       "      <td>-0.664626</td>\n",
       "      <td>0.441134</td>\n",
       "      <td>-0.244352</td>\n",
       "      <td>0.681439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199998</th>\n",
       "      <td>0.130722</td>\n",
       "      <td>0.084619</td>\n",
       "      <td>1.031319</td>\n",
       "      <td>0.550924</td>\n",
       "      <td>0.895317</td>\n",
       "      <td>0.300732</td>\n",
       "      <td>0.204020</td>\n",
       "      <td>1.463568</td>\n",
       "      <td>0.958981</td>\n",
       "      <td>1.079431</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.235373</td>\n",
       "      <td>-0.585681</td>\n",
       "      <td>1.077122</td>\n",
       "      <td>0.314132</td>\n",
       "      <td>0.357592</td>\n",
       "      <td>0.665391</td>\n",
       "      <td>-0.657032</td>\n",
       "      <td>0.527681</td>\n",
       "      <td>-0.263055</td>\n",
       "      <td>0.614511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199999</th>\n",
       "      <td>0.151005</td>\n",
       "      <td>0.088916</td>\n",
       "      <td>1.045568</td>\n",
       "      <td>0.551447</td>\n",
       "      <td>0.902669</td>\n",
       "      <td>0.296765</td>\n",
       "      <td>0.194556</td>\n",
       "      <td>1.475017</td>\n",
       "      <td>0.953509</td>\n",
       "      <td>1.071944</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.179322</td>\n",
       "      <td>-0.573430</td>\n",
       "      <td>1.052131</td>\n",
       "      <td>0.372877</td>\n",
       "      <td>0.327950</td>\n",
       "      <td>0.633775</td>\n",
       "      <td>-0.634084</td>\n",
       "      <td>0.628486</td>\n",
       "      <td>-0.287700</td>\n",
       "      <td>0.552503</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200000 rows Ã— 90 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5         6   \\\n",
       "0       1.060983 -0.249232  0.033320 -0.003673  0.717194  1.046063  0.610880   \n",
       "1       1.055380 -0.241545  0.043931 -0.020404  0.787182  1.059425  0.642775   \n",
       "2       1.049613 -0.227252  0.060362 -0.036550  0.858226  1.069472  0.671495   \n",
       "3       1.043500 -0.206530  0.082012 -0.051347  0.929366  1.075283  0.696153   \n",
       "4       1.036902 -0.179899  0.108162 -0.063958  0.999676  1.076241  0.715926   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "199995  0.064257  0.065702  0.992203  0.557008  0.867911  0.322929  0.235827   \n",
       "199996  0.087371  0.072969  1.004596  0.553764  0.878036  0.313668  0.224850   \n",
       "199997  0.109518  0.079295  1.017653  0.551714  0.887140  0.306317  0.214181   \n",
       "199998  0.130722  0.084619  1.031319  0.550924  0.895317  0.300732  0.204020   \n",
       "199999  0.151005  0.088916  1.045568  0.551447  0.902669  0.296765  0.194556   \n",
       "\n",
       "              7         8         9   ...        80        81        82  \\\n",
       "0       0.881125 -0.095760  1.208036  ...  1.287039  0.835713  0.230009   \n",
       "1       0.824348 -0.074474  1.230836  ...  1.288494  0.949028  0.215377   \n",
       "2       0.763695 -0.057550  1.249672  ...  1.297449  1.066072  0.201506   \n",
       "3       0.701332 -0.045229  1.264819  ...  1.295591  1.155701  0.167765   \n",
       "4       0.639420 -0.037566  1.276671  ...  1.260132  1.200473  0.100077   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "199995  1.436795  0.970282  1.104490  ... -0.346586 -0.566914  1.144641   \n",
       "199996  1.444529  0.967536  1.095734  ... -0.320804 -0.582517  1.124550   \n",
       "199997  1.453414  0.963708  1.087367  ... -0.283037 -0.588845  1.101614   \n",
       "199998  1.463568  0.958981  1.079431  ... -0.235373 -0.585681  1.077122   \n",
       "199999  1.475017  0.953509  1.071944  ... -0.179322 -0.573430  1.052131   \n",
       "\n",
       "              83        84        85        86        87        88        89  \n",
       "0       0.408131  0.915408  0.979728  0.321034 -0.053301  0.046553  0.741576  \n",
       "1       0.419659  0.920888  0.938208  0.465689 -0.180783 -0.155095  0.738815  \n",
       "2       0.379826  0.869458  0.857093  0.613904 -0.254435 -0.353925  0.800326  \n",
       "3       0.301866  0.753864  0.760580  0.732424 -0.240733 -0.494130  0.924109  \n",
       "4       0.216509  0.589493  0.684383  0.785061 -0.133949 -0.528797  1.082124  \n",
       "...          ...       ...       ...       ...       ...       ...       ...  \n",
       "199995  0.126556  0.530678  0.739130 -0.623557  0.313669 -0.228914  0.821861  \n",
       "199996  0.190273  0.459681  0.720689 -0.654188  0.369592 -0.232887  0.751271  \n",
       "199997  0.253078  0.401736  0.695244 -0.664626  0.441134 -0.244352  0.681439  \n",
       "199998  0.314132  0.357592  0.665391 -0.657032  0.527681 -0.263055  0.614511  \n",
       "199999  0.372877  0.327950  0.633775 -0.634084  0.628486 -0.287700  0.552503  \n",
       "\n",
       "[200000 rows x 90 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduced_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
